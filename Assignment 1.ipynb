{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib\n",
      "matplotlib.use('Agg')\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 386
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x=np.arange(0,100.0).reshape((100,1))\n",
      "y=100*x\n",
      "for i in range(0,100):\n",
      "    y[i,0]+=2*np.random.randn(1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 388
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def Norm(x):\n",
      "    n=x.shape[0]\n",
      "    norm=0\n",
      "    for i in range(0,n):\n",
      "        norm+=x[i,0]*x[i,0]\n",
      "    return norm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 389
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def MatrixMultiply(a,b):\n",
      "    n1=a.shape\n",
      "    n2=b.shape\n",
      "    \n",
      "    if n1[1]!=n2[0]:\n",
      "        print 'Dimensions don\\'t match!!'\n",
      "        return 0\n",
      "    else:\n",
      "        c=np.zeros((n1[0],n2[1]))\n",
      "        for i in range(0,n1[0]):\n",
      "            for j in range(0,n2[1]):\n",
      "                for k in range(0,n1[1]):\n",
      "                    c[i][j]+=a[i][k]*b[k][j]\n",
      "                \n",
      "        return c"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 390
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def BatchGradientDescentTraining(X,Y,scaled,learning_rate,stopping_criterion,max_iterations):\n",
      "    dim=X.shape\n",
      "    n=dim[0]\n",
      "    m=dim[1]\n",
      "    \n",
      "    if(scaled==0):\n",
      "        X_min=np.min(X,axis=0)\n",
      "        X_max=np.max(X,axis=0)\n",
      "        Y_min=np.min(Y,axis=0)\n",
      "        Y_max=np.max(Y,axis=0)\n",
      "        \n",
      "        X_t=np.zeros(X.shape)\n",
      "        \n",
      "        for i in range(0,m):\n",
      "            if(X_min[i]==X_max[i]):\n",
      "                X_t[:,i]=X[:,i]\n",
      "                continue\n",
      "            else:\n",
      "                X_t[:,i]=X[:,i]-X_min[i]\n",
      "                X_t[:,i]/=(X_max[i]-X_min[i])\n",
      "        \n",
      "        Y_t=Y-Y_min\n",
      "        Y_t/=(Y_max-Y_min)\n",
      "        \n",
      "        Y_t=Y_t.reshape((n,1))\n",
      "    \n",
      "        stopping_criterion*=(X_max[i]-X_min[i])/(Y_max-Y_min)\n",
      "    else:\n",
      "        X_t=X\n",
      "        Y_t=Y\n",
      "    \n",
      "    I=np.identity(m)\n",
      "    W=np.zeros(m).reshape((m,1))\n",
      "    temp=2*np.sqrt(stopping_criterion)*np.ones(m).reshape((m,1))\n",
      "    \n",
      "    P=I-learning_rate*MatrixMultiply(X_t.transpose(),X_t)/n\n",
      "    Q=learning_rate*MatrixMultiply(X_t.transpose(),Y_t)/n\n",
      "    \n",
      "    iteration=0\n",
      "    while(Norm(W-temp)>stopping_criterion and iteration<max_iterations):\n",
      "        temp=W\n",
      "        W=MatrixMultiply(P,temp)+Q\n",
      "        iteration+=1\n",
      "#         print iteration\n",
      "    b=0\n",
      "    if(scaled==0):    \n",
      "        for i in range(0,m):\n",
      "            if(X_min[i]==X_max[i]):\n",
      "                continue\n",
      "            else:\n",
      "                W[i]*=(Y_max-Y_min)/(X_max[i]-X_min[i])\n",
      "                b-=W[i]*X_min[i]\n",
      "        b+=Y_min\n",
      "    \n",
      "    return [W,b]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 366
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "w=BatchGradientDescentTraining(x,y,0,0.1,0.0000001,1000000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 391
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "w"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 392,
       "text": [
        "[array([[ 99.91988907]]), array([-0.56694817])]"
       ]
      }
     ],
     "prompt_number": 392
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def StochasticGradientDescentTraining(X,Y,scaled,learning_rate,max_epochs):\n",
      "    dim=X.shape\n",
      "    n=dim[0]\n",
      "    m=dim[1]\n",
      "    \n",
      "    if(scaled==0):\n",
      "        X_min=np.min(X,axis=0)\n",
      "        X_max=np.max(X,axis=0)\n",
      "        Y_min=np.min(Y,axis=0)\n",
      "        Y_max=np.max(Y,axis=0)\n",
      "        \n",
      "        X_t=np.zeros(X.shape)\n",
      "        \n",
      "        for i in range(0,m):\n",
      "            if(X_min[i]==X_max[i]):\n",
      "                X_t[:,i]=X[:,i]\n",
      "                continue\n",
      "            else:\n",
      "                X_t[:,i]=X[:,i]-X_min[i]\n",
      "                X_t[:,i]/=(X_max[i]-X_min[i])\n",
      "        \n",
      "        Y_t=Y-Y_min\n",
      "        Y_t/=(Y_max-Y_min)\n",
      "        \n",
      "    else:\n",
      "        X_t=X\n",
      "        Y_t=Y\n",
      "        \n",
      "    W=np.zeros(m)\n",
      "    \n",
      "    for i in range(0,max_epochs):\n",
      "        for j in range(0,n):\n",
      "            W-=learning_rate*X_t[j,:]*(np.dot(W,X_t[j,:]) - Y_t[j])\n",
      "    \n",
      "    b=0\n",
      "    if(scaled==0):    \n",
      "        for i in range(0,m):\n",
      "            if(X_min[i]==X_max[i]):\n",
      "                continue\n",
      "            else:\n",
      "                W[i]*=(Y_max-Y_min)/(X_max[i]-X_min[i])\n",
      "                b-=W[i]*X_min[i]\n",
      "        b+=Y_min\n",
      "    \n",
      "    return [W,b]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 393
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "w=StochasticGradientDescentTraining(x,y,0,0.1,10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 394
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "w"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 395,
       "text": [
        "[array([ 100.01022048]), array([-0.56694817])]"
       ]
      }
     ],
     "prompt_number": 395
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x=10*np.transpose(np.array([np.arange(0,1000),np.arange(0,1000)]))\n",
      "y=x[:,0]+x[:,1]+np.random.randn(1000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 396
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "BatchGradientDescentTraining(x,y,0,0.1,0.0000001,100000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 397,
       "text": [
        "[array([[ 0.99577515],\n",
        "       [ 0.99577515]]), array([-0.83424151])]"
       ]
      }
     ],
     "prompt_number": 397
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "StochasticGradientDescentTraining(x,y,0,0.1,10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 398,
       "text": [
        "[array([ 1.00006851,  1.00006851]), -0.83424150819232268]"
       ]
      }
     ],
     "prompt_number": 398
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data=pd.read_csv('assignment1.csv')\n",
      "data=data.dropna(axis=0,how='any')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 351
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y=data['Regressor']\n",
      "x=data[['Var1','Var2','Var3','Var4','Var5','Var6','Var7']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 352
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data=np.loadtxt('assignment1.csv',delimiter=',',skiprows=1)\n",
      "data=data[~np.isnan(data).any(axis=1)]\n",
      "y=data[:,1]\n",
      "x=data[:,2:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 399
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "StochasticGradientDescentTraining(x,y,0,0.000001,10000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 407,
       "text": [
        "[array([  2.86811653e-01,   1.24100372e-04,   6.76546749e-03,\n",
        "         3.20464062e-04,   5.12239837e-01,   8.89363863e-01,\n",
        "         4.22080431e+00]),\n",
        " -63.271187261127764]"
       ]
      }
     ],
     "prompt_number": 407
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import linear_model"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 376
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = linear_model.LinearRegression()\n",
      "\n",
      "model.fit(x,y)\n",
      "model.coef_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 403,
       "text": [
        "array([-0.49337632,  0.01989564, -0.01695114, -0.00647404,  0.08057584,\n",
        "        0.75077268,  1.4261405 ])"
       ]
      }
     ],
     "prompt_number": 403
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}